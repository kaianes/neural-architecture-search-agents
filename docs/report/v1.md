# üìò Project Explanation and Overview

## üéØ Objective

The purpose of this project, **Efficient Deep Neural Network Architecture Search Using AI Agents**, is to create an intelligent system that can automatically design and optimize deep neural networks (DNNs). Instead of manually deciding the number of layers, neurons, or hyperparameters, AI agents will handle these tasks autonomously, improving both **efficiency** and **sustainability**.

The project aims to reduce human intervention in DNN design and minimize the computational cost of model search, aligning with **Green AI** principles that focus on energy-efficient and eco-friendly AI research.

---

## ‚öôÔ∏è What‚Äôs Happening During Execution

When you run the command:

```bash
python src/main.py --config experiments/configs/baseline.yaml
```

the following process unfolds:

### 1. **Configuration Loading**

The system reads the YAML configuration file (`baseline.yaml`) to get all experiment parameters‚Äîdataset type, training setup, search strategy, and file paths.

### 2. **Environment Initialization**

The script sets a random seed for reproducibility and selects the best available device (CPU or GPU). All required directories for results and artifacts are created automatically.

### 3. **Neural Architecture Search (NAS) Begins**

An AI agent (in this baseline, using **Optuna**) starts trying out different neural network configurations. For each trial:

* A **SimpleCNN** model is created with random hyperparameters (e.g., kernel size, channels, dropout rate).
* The model is trained for a few epochs on the chosen dataset (e.g., MNIST).
* Validation accuracy is measured and reported back to the NAS agent.

### 4. **Optimization and Selection**

Optuna evaluates all trials, tracking accuracy and computational metrics (like parameters and FLOPs). Once the trials finish, it identifies the **best model configuration**.

### 5. **Logging and Reporting**

Results‚Äîincluding accuracy, parameters, FLOPs, and energy consumption (if available)‚Äîare logged for analysis. The system outputs the best configuration and saves it for later use or further optimization.

---

## üß† Meaning of the Tools Used

| Tool / Library              | Purpose                     | Description                                                                                 |
| --------------------------- | --------------------------- | ------------------------------------------------------------------------------------------- |
| **PyTorch**                 | Deep Learning Framework     | Used to build, train, and evaluate neural network models (e.g., SimpleCNN).                 |
| **Optuna**                  | Hyperparameter Optimization | Conducts the automated search for optimal architectures by testing multiple configurations. |
| **TorchVision**             | Dataset & Model Utilities   | Provides built-in datasets (MNIST, CIFAR) and preprocessing tools.                          |
| **THOP**                    | FLOPs Calculator            | Estimates the computational complexity of a model by counting floating-point operations.    |
| **CodeCarbon** *(optional)* | Carbon Tracking             | Measures energy use and CO‚ÇÇ emissions during training to promote sustainability.            |
| **Rich**                    | Console Logging             | Enhances terminal outputs with color and formatting for better readability.                 |
| **YAML**                    | Configuration Language      | Stores experiment parameters and paths in a readable format.                                |
| **TQDM**                    | Progress Bars               | Displays real-time training progress during each NAS trial.                                 |

---

## üîç Simplified Flow Summary

```
Configuration ‚Üí Dataset Loading ‚Üí Agent (Optuna) ‚Üí Model Trials ‚Üí Evaluation ‚Üí Best Architecture ‚Üí Logging
```

1. **Load config:** reads YAML settings.
2. **Prepare dataset:** downloads and loads MNIST/CIFAR.
3. **Run trials:** Optuna explores different CNN designs.
4. **Evaluate:** measures accuracy and FLOPs.
5. **Select:** saves the best-performing design.

---

## üåø Why It Matters

* **Automation:** Reduces human workload in DNN design.
* **Efficiency:** Finds high-performing architectures with fewer experiments.
* **Sustainability:** Tracks and minimizes computational waste.
* **Scalability:** Framework can be extended to larger datasets or more complex NAS strategies.

---

This explanation provides a conceptual understanding of what happens when running the codebase, the tools involved, and how each component contributes to the project‚Äôs objective of building an **autonomous, efficient, and sustainable AI-driven NAS system**.
